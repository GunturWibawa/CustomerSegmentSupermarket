{"cells":[{"cell_type":"markdown","source":["# **Customer Segmentation of Good Seed Retail Supermarket**"],"metadata":{"id":"tcs84qSHg4yX"}},{"cell_type":"markdown","source":["# Project Goals\n","\n","Good Seed a supermarket chain wanted to see if Data Science could help them to comply with the law by ensuring that they weren't selling age-restricted products to underage customers. We also asked to carry out an evaluation. Therefore, when we start to work, remember the following:\n","\n","- Stores from this franchise are equipped with a camera in the cashier area that will display a signal when someone buys a product with an age limit\n","- Computer vision methods can be used to determine a person's age from a photograph\n","- Our task is to build and evaluate a model to verify a person's age\n","\n","To begin the task, we have a set of people photos along with their ages."],"metadata":{"id":"nE90V2mKg7bE"}},{"cell_type":"markdown","source":["# Project Instructions\n","\n","The following is the project implementation plan:\n","\n","1. Perform an exploratory data analysis to understand the overview of the dataset.\n","2. Train and evaluate the model (this process needs to be completed on the GPU platform).\n","3. Merge your code, both for the output and findings (from the previous points) in the final Jupyter Notebook file.\n","4. Make a conclusion from the model evaluation, then add the conclusion to the notebook."],"metadata":{"id":"bd075EQNg9nt"}},{"cell_type":"markdown","metadata":{"id":"E6HfvNR6MmaZ"},"source":["## Initialization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0UeTRAvXMmac"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import tensorflow as tf\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import seaborn as sns\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.resnet import ResNet50\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n","from tensorflow.keras.optimizers import Adam"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HqvZaXRtMmac"},"outputs":[],"source":["%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","# the next line provides better quality graphics on HiDPI screens\n","\n","plt.style.use('default')"]},{"cell_type":"markdown","metadata":{"id":"7sJmKfmUMmad"},"source":["## 1. Data Preparations"]},{"cell_type":"markdown","metadata":{"id":"J__bE6bjMmad"},"source":["The *dataset* you need is stored in the `/datasets/faces/` folder. In that folder, you can find:\n","- `final_files` folder with 7.6k photos\n","- *File* `labels.csv` which contains labels, with two columns: `file_name` and `real_age`\n","\n","Given the large number of *image* files, it is recommended that you do not read them all at once, as this will only use up computing resources. We recommend you to create a generator with ImageDataGenerator.\n","\n","The label *file* can be loaded as a normal CSV *file*."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v0SLg7FJMmad"},"outputs":[],"source":["data_root_path = '/datasets/faces/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G2OT9wLnMmad"},"outputs":[],"source":["labels = pd.read_csv(data_root_path + 'labels.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DABgXT7FMmae"},"outputs":[],"source":["labels.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A9YsW7SvMmae"},"outputs":[],"source":["labels.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CFP5FJ0mMmaf"},"outputs":[],"source":["labels.describe(percentiles=[.1, .05, .25, .75, .95, .99]).round(1).T"]},{"cell_type":"markdown","metadata":{"id":"_DCEzqKcMmag"},"source":["**Conclusion**\n","\n","- There is no missing value or abnormal data in the `real_age` column. It does not require any correction\n","- The dataset is not too big for the Neural Network model, it may require a data augmentation step or freezing layer"]},{"cell_type":"markdown","metadata":{"id":"vKJg0_vpMmag"},"source":["## 2. Exploratory Data Analysis"]},{"cell_type":"markdown","metadata":{"id":"raJI-NxXMmag"},"source":["We already know the `real_age` column is a feature with a value does not exceed 100, so we can calculate its exact value to see its distribution."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nFQ3hjerMmah"},"outputs":[],"source":["def create_gen_flow(min_age=0, max_age=100):\n","\n","    datagen = ImageDataGenerator(rescale=1./255)\n","\n","    gen_flow = datagen.flow_from_dataframe(\n","        dataframe=labels.query('real_age >= @min_age and real_age <= @max_age'),\n","        directory=data_root_path + 'final_files',\n","        x_col='file_name',\n","        y_col='real_age',\n","        target_size=(224, 224),\n","        batch_size=16,\n","        class_mode='raw',\n","        seed=12345)\n","\n","    return gen_flow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sD0gU75tMmah"},"outputs":[],"source":["# Count the missing value from the `age` column and fill it with 0\n","\n","dft1 = labels['real_age'].value_counts().sort_index().reindex(np.arange(0, 101)).fillna(0).astype('int')\n","dft1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oLagclJWMmah"},"outputs":[],"source":["# Grouped the numbers using range 0-4, 5-9, etc\n","\n","dft2 = pd.cut(labels['real_age'], np.arange(0, 101, 5), right=False).value_counts().sort_index()\n","dft2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nu4JP4iSMmah"},"outputs":[],"source":["fig, axs = plt.subplots(2, 1, figsize=(15, 10))\n","\n","ax = axs[0]\n","dft1.plot(kind='bar', ax=ax)\n","\n","ax = axs[1]\n","dft2.plot(kind='bar', ax=ax)\n","\n","fig.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"92GComTyMmah"},"source":["**Conclusion**\n","\n","1. There are only a few elderly people in the sample above. This may be because the model has not been properly trained for the elderly category. At the same time, the number of errors that occur may be significant. It's hard to say if we compare between the ages of 80 to 90 years and the ages of 0 to 10 years.\n","2. There are some people with very old age. Will it be considered as outliers?. Maybe this is because some people's real ages cannot be known, and fill them with specific values. So, do not get confused when training the model, we will drop this data.\n","3. There are 2 - 4 clusters on the histogram. This may happened because the data obtained from many sources, for example; there is one source that only records children under 10 years old, and another source records people over 10 years of age. Maybe, because there are several images taken from different sources, because it requires different preprocessing techniques.\n","4. We should try to check some images randomly to narrow down some of the findings above."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h6vGerpcMmah"},"outputs":[],"source":["def show_batch(batch, predictions=None):\n","\n","    rows = 3\n","    cols = 5\n","    fig, axs = plt.subplots(rows, cols, figsize=(10, 6))\n","\n","    for i in range(15):\n","\n","        row = i // cols\n","        col = i % cols\n","        ax = axs[row][col]\n","        ax.imshow(batch[0][i])\n","        real_age = batch[1][i]\n","        if predictions is None:\n","            title = f'age: {real_age}'\n","        else:\n","            title = f'age: {real_age}, pred: {round(predictions[i])}'\n","        ax.set_title(title, fontsize='medium')\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        ax.set_xticklabels([])\n","        ax.set_yticklabels([])\n","\n","    fig.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ln59d3nMmah"},"outputs":[],"source":["gen_flow_0_9 = create_gen_flow(min_age=0, max_age=9)\n","gen_flow_10_79 = create_gen_flow(min_age=10, max_age=79)\n","gen_flow_80_100 = create_gen_flow(min_age=80, max_age=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l8sDoYYQMmah"},"outputs":[],"source":["show_batch(next(gen_flow_0_9))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dsBmnw0RMmah"},"outputs":[],"source":["show_batch(next(gen_flow_10_79))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nus7qotgMmah"},"outputs":[],"source":["show_batch(next(gen_flow_80_100))"]},{"cell_type":"markdown","metadata":{"id":"mHn_YkkBMmai"},"source":["### Findings"]},{"cell_type":"markdown","metadata":{"id":"FIs2h7Y2Mmai"},"source":["1. The size of the photo above is auto adjusted to 224x224, it needs to be done to use a trained model as it seen on ImageNet.\n","2. The image is already in the correct position.\n","3. The dataset has photos of different quality: there are old, black and white, and color images. It makes sense to augment using black and white photos with percentages in certain cases. Maybe we can add brightness augmentation, or use a color shade.\n","4. The faces in the dataset has different sizes: the pictures above require a zoom augmentation.\n","5. We have to use `horizontal_flip` and no need to use `vertical_flip`."]},{"cell_type":"markdown","metadata":{"id":"HcRlYkqlMmai"},"source":["## 3. Data Modelling"]},{"cell_type":"markdown","metadata":{"id":"aLFdiBHxMmai"},"source":["Define the necessary functions to train your model on the GPU platform and create a single script that contains all of these functions with an initialization section.\n","\n","To make it easier, you can define it in this *notebook* and run the ready-to-use code in the next section to build the scripts automatically."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Du6u9I2KMmai"},"outputs":[],"source":["gpus = tf.config.list_physical_devices(\"GPU\")\n","\n","if gpus:\n","\n","    try:\n","        tf.config.experimental.set_virtual_device_configuration(\n","            gpus[0],\n","            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit = 1024 * 8)]\n","        )\n","    except RunTimeError as e:\n","        print(e)\n","\n","\n","logical_gpus = tf.config.list_logical_devices('GPU')\n","print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gCJmpa2wMmai"},"outputs":[],"source":["def load_train(path):\n","    labels = pd.read_csv(path + 'labels.csv')\n","\n","    train_datagen = ImageDataGenerator(\n","        validation_split=0.25,\n","        horizontal_flip=True,\n","        rescale=1./255)\n","\n","    train_gen_flow = train_datagen.flow_from_dataframe(\n","            dataframe=labels,\n","            directory=path + 'final_files/',\n","            x_col='file_name',\n","            y_col='real_age',\n","            target_size=(224, 224),\n","            batch_size=16,\n","            class_mode='raw',\n","            subset='training',\n","            seed=12345)\n","\n","    return train_gen_flow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k2fOZkkVMmai"},"outputs":[],"source":["def load_test(path):\n","    labels = pd.read_csv(path + 'labels.csv')\n","\n","    test_datagen = ImageDataGenerator(\n","        validation_split=0.25,\n","        rescale=1./255)\n","\n","    test_gen_flow = test_datagen.flow_from_dataframe(\n","            dataframe=labels,\n","            directory=path + 'final_files/',\n","            x_col='file_name',\n","            y_col='real_age',\n","            target_size=(224, 224),\n","            batch_size=16,\n","            class_mode='raw',\n","            subset='validation',\n","            seed=12345)\n","\n","    return test_gen_flow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E8hHgDxeMmai"},"outputs":[],"source":["def create_model(input_shape):\n","    backbone = ResNet50(input_shape=input_shape,\n","                        weights='imagenet',\n","                        include_top=False)\n","\n","    model = Sequential()\n","    model.add(backbone)\n","    model.add(GlobalAveragePooling2D())\n","    model.add(Dense(1, activation='relu'))\n","\n","    optimizer = Adam(learning_rate=0.0005)\n","\n","    model.compile(\n","        optimizer=optimizer,\n","        loss='mse',\n","        metrics=['mae']\n","    )\n","\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k_tzatzHMmaj"},"outputs":[],"source":["def train_model(model, train_data, test_data, batch_size=None, epochs=20,\n","                steps_per_epoch=None, validation_steps=None):\n","\n","    if steps_per_epoch is None:\n","        steps_per_epoch = len(train_data)\n","    if validation_steps is None:\n","        validation_steps = len(test_data)\n","\n","    model.fit(train_data,\n","              validation_data=test_data,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              steps_per_epoch=steps_per_epoch,\n","              validation_steps=validation_steps,\n","              verbose=2)\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"HYARdhxQMmaj"},"source":["# 4. Preparing scripts to run on GPU platforms"]},{"cell_type":"markdown","metadata":{"id":"CX8eTaIEMmaj"},"source":["Once you have defined the required functions, you can create a script for the GPU platform, download it via the \"File|Open...\" menu, and upload it later to run on the GPU platform.\n","\n","Note: Your script must also include an initialization section. An example is shown below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3D7NLsTrMmaj"},"outputs":[],"source":["# prepare the script to run on the GPU platform\n","\n","\n","init_str = \"\"\"\n","import pandas as pd\n","\n","import tensorflow as tf\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.resnet import ResNet50\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n","from tensorflow.keras.optimizers import Adam\n","\"\"\"\n","\n","import inspect\n","\n","with open('run_model_on_gpu.py', 'w') as f:\n","\n","    f.write(init_str)\n","    f.write('\\n\\n')\n","\n","    for fn_name in [load_train, load_test, create_model, train_model]:\n","\n","        src = inspect.getsource(fn_name)\n","        f.write(src)\n","        f.write('\\n\\n')"]},{"cell_type":"markdown","metadata":{"id":"19tniDvOMmaj"},"source":["**Running on the local platform**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eCXsn_waMmak"},"outputs":[],"source":["train_data = load_train('/datasets/faces/')\n","test_data = load_test('/datasets/faces/')\n","model = create_model((224, 224, 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fd25Ui9-Mmak"},"outputs":[],"source":["model = train_model(model, train_data, test_data)"]},{"cell_type":"markdown","metadata":{"id":"8d71UU2jMmak"},"source":["### Output"]},{"cell_type":"markdown","metadata":{"id":"aKTj0l9mMmak"},"source":["Put the output after model compiled on the platform"]},{"cell_type":"markdown","metadata":{"id":"ws-JYwnQMmak"},"source":["Train for 356 steps, validate for 119 steps\n","\n","Epoch 1/20\n","\n","2023-06-21 07:06:55.782610: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","\n","2023-06-21 07:06:56.898439: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","\n","356/356 - 68s - loss: 215.6398 - mae: 11.1068 - val_loss: 583.3328 - val_mae: 19.0945\n","\n","Epoch 2/20\n","\n","356/356 - 40s - loss: 132.3415 - mae: 8.8419 - val_loss: 311.3901 - val_mae: 13.1113\n","\n","Epoch 3/20\n","\n","356/356 - 40s - loss: 109.1058 - mae: 7.9951 - val_loss: 102.4170 - val_mae: 7.7248\n","\n","Epoch 4/20\n","\n","356/356 - 40s - loss: 93.8632 - mae: 7.4255 - val_loss: 129.1637 - val_mae: 8.6758\n","\n","Epoch 5/20\n","\n","356/356 - 40s - loss: 76.3025 - mae: 6.6940 - val_loss: 136.8477 - val_mae: 8.9292\n","\n","Epoch 6/20\n","\n","356/356 - 40s - loss: 69.8559 - mae: 6.4129 - val_loss: 152.5951 - val_mae: 9.2539\n","\n","Epoch 7/20\n","\n","356/356 - 40s - loss: 58.4601 - mae: 5.9017 - val_loss: 104.7878 - val_mae: 7.6880\n","\n","Epoch 8/20\n","\n","356/356 - 40s - loss: 47.7391 - mae: 5.2862 - val_loss: 91.9892 - val_mae: 7.2369\n","\n","Epoch 9/20\n","\n","356/356 - 41s - loss: 41.1969 - mae: 4.9105 - val_loss: 98.6631 - val_mae: 7.6760\n","\n","Epoch 10/20\n","\n","356/356 - 40s - loss: 38.6897 - mae: 4.8129 - val_loss: 117.9522 - val_mae: 8.0097\n","\n","Epoch 11/20\n","\n","356/356 - 40s - loss: 32.2490 - mae: 4.3630 - val_loss: 108.9115 - val_mae: 8.0470\n","\n","Epoch 12/20\n","\n","356/356 - 40s - loss: 27.2420 - mae: 4.0149 - val_loss: 90.8630 - val_mae: 7.2213\n","\n","Epoch 13/20\n","\n","356/356 - 40s - loss: 25.3628 - mae: 3.8951 - val_loss: 107.5655 - val_mae: 7.7021\n","\n","Epoch 14/20\n","\n","356/356 - 40s - loss: 25.6134 - mae: 3.8729 - val_loss: 86.8082 - val_mae: 7.1625\n","\n","Epoch 15/20\n","\n","356/356 - 40s - loss: 24.2496 - mae: 3.7773 - val_loss: 86.9447 - val_mae: 7.1203\n","\n","Epoch 16/20\n","\n","356/356 - 40s - loss: 20.1285 - mae: 3.4582 - val_loss: 106.0632 - val_mae: 7.7228\n","\n","Epoch 17/20\n","\n","356/356 - 40s - loss: 19.1883 - mae: 3.3468 - val_loss: 90.7546 - val_mae: 7.0499\n","\n","Epoch 18/20\n","\n","356/356 - 40s - loss: 17.4581 - mae: 3.2225 - val_loss: 75.6543 - val_mae: 6.6111\n","\n","Epoch 19/20\n","\n","356/356 - 40s - loss: 17.9511 - mae: 3.2723 - val_loss: 80.1560 - val_mae: 6.8503\n","\n","Epoch 20/20\n","\n","356/356 - 40s - loss: 17.0490 - mae: 3.1716 - val_loss: 83.3315 - val_mae: 6.9683\n","\n","WARNING:tensorflow:sample_weight modes were coerced from\n","\n","  ...\n","\n","    to  \n","\n","  ['...']\n","\n","119/119 - 10s - loss: 83.3315 - mae: 6.9683\n","\n","Test MAE: 6.9683\n"]},{"cell_type":"markdown","metadata":{"id":"M0kLh3QoMmal"},"source":["## 5 Overall Conclusion"]},{"cell_type":"markdown","metadata":{"id":"alGPl3hGMmal"},"source":["1. The model is well trained when performed using MSE as a loss function. The steps in Adam's algorithm must be slightly reduced for better convergence.\n","\n","2. We don't need to freeze the layer, but we still have to do augmentation.\n","\n","3. The model above has quite a lot of overfitting, because of its complexity, it can be assumed that it's normal. It still can be met the expected quality.\n","\n","4. The quality of the validation is not very stable, but can slowly decrease. This may be due to the rather small and heterogeneous samples\n","\n","5. It is very difficult to meet MAE close to zero. Of course, it is very difficult for someone to determine the age of many images, and maybe it is because we do not have enough information related to the photos, and below a certain threshold the expected quality is often can not be obtained."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}